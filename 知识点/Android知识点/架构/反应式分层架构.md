# 反应式分层架构（响应式编程）

原文：https://zhuanlan.zhihu.com/p/96603046

## **1 什么是反应式？**

### **1.1 反应式介绍**

为了直观地了解什么是反应式，我们先从一个大家都比较熟悉的类比开始。首先打开Excel，在B、C、D三列输入如下公式：

![img](https://pic2.zhimg.com/80/v2-38cec9f231bdee6096aa842bbf41d3d9_720w.webp)

B、C和D三列每个单元格的值均依赖其左侧的单元格，当我们在A列依次输入1、2和3时，变化会自动传递到了B、C和D三列，并触发相应状态变更，如下图：

![img](https://pic4.zhimg.com/80/v2-53315657a08ac53aa0229f6ae2429023_720w.webp)

我们可以把A列从上到下想象成一个数据流，每一个数据到达时都会触发一个事件，该事件会被传播到右侧单元格，后者则会处理事件并改变自身的状态。这一系列流程其实就是反应式的核心思想。

核心思想：实时相应输入的数据流。

维基百科关于反应式编程的定义：

> 反应式编程 (reactive programming) 是一种基于数据流 (data stream) 和 变化传递 (propagation of change) 的声明式 (declarative) 的编程范式。

 更准确地说，异步数据流(asynchronous data stream)或者说反应式流(reactive stream)才是反应式编程的最佳实践。

而观察者模式是实现反应式的一种手段

### 1.3 ReactiveX 介绍

ReactiveX是Reactive Extensions的缩写，一般简写为Rx。Rx是一个编程模型，目标是提供一致的编程接口，帮助开发者更方便的处理异步数据流。Rx支持几乎全部的流行编程语言。

### 1.5 Reactive Streams

Reactive Streams的目标是定义一组最小化的异步流处理接口，使得在不同框架之间，甚至不同语言之间实现交互性。该规范已经成为了业界标准， 并且在Java 9中已经实现，对应的实现接口为java.util.concurrent.Flow。但这并不意味着像RxJava、Reactor、Akka Streams这些流处理框架就没有意义了，事实上恰恰相反。

Reactive Streams的目的在于增强不同框架之间的交互性，提供的是一组最小功能集合，无法满足我们日常的流处理需求，例如组合、过滤、缓存、限流等功能都需要额外实现。

## 2 为什么需要反应式？

### 2.1 命令式编程 VS 声明式编程

命令式编程就是对硬件操作的抽象， 程序员需要通过指令，精确的告诉计算机干什么事情。

声明式编程是解决程序员的利器，声明式编程更关注我想要什么(What)而不是怎么去做(How)。SQL是最典型的声明式语言，我们通过SQL描述想要什么，最终由数据库引擎执行SQL语句并将结果返回给我们。

```text
SELECT COUNT(*)  FROM USER u  WHERE u.age > 30
```

反应式架构推荐使用声明式编程， 使用更接近自然语言的方式描述业务逻辑， 代码清晰易懂并且富有表达力， 最重要的是大大降低了后期维护成本。

### 2.2 同步编程 VS 异步编程

 阻塞与非阻塞关注方法执行时当前线程的状态，而同步与异步则关注方法调用结果的通知机制。因为是从不同角度描述方法的调用过程，所以这两组概念也可以相互组合，即将线程状态和通知机制进行组合。

反应式架构的核心思想是异步非阻塞的反应式流，作为过渡阶段，我们可以选择先对系统进行完全异步化重构，为进一步向反应式架构演进奠定基础。

### 2.4 同步编程面临的挑战

传统应用通常基于Servlet容器进行部署，而Servlet是基于线程的请求处理模型。从上文的讨论中我们发现，通常需要设置一个较大的线程池以获得较好的性能，较大的线程池会导致以下三个问题：

- 额外的内存开销。 在Java中，每个线程都有自己的栈空间，默认是1MB。如果设置线程池大小为200，则应用在启动时至少需要200M内存，一方面造成了内存浪费，另一方面也导致应用启动变慢。试想一下，如果同时部署1000个节点，这些问题将会被放大1000倍。
- CPU利用率低。 有两个方面原因会导致极低的CPU利用率。一方面是在Oracle JDK 1.2版本之后，所有平台的JVM实现都使用1:1线程模型(Solaris是个特例)，这意味着一个Java线程会被映射到一个轻量级进程上，而有效的轻量级进程数量取决于CPU的个数以及核数。如果Java的线程数量远大于有效的轻量级进程数量，则频繁的线程上限文切换会浪费大量CPU时间； 另一方面，由于传统的远程操作或IO操作均为阻塞操作，会导致执行线程被挂起从而无法执行其他任务，大大降低了CPU的利用率。
- 资源竞争激烈。 当增大线程池后，其他的共享资源便会成为性能瓶颈，如数据库连接池资源。如果存在共享资源瓶颈，即使设置再大的线程池，也无法有效地提升性能。此时会导致多个线程竞争数据库连接， 使得数据库连接成为系统瓶颈。

除了上面这些问题，同步编程还会深刻地影响到我们的架构。

在实际使用的时候，当相应过多时，会导致微服务调用链雪崩。

其实所有问题的根源都可以归结为传统的同步阻塞编程方式。尤其是在微服务场景下，随着调用链长度的不断增长，风险也将越来越高， 其中任何一个节点同步阻塞操作都会导致其下游所有节点线程被阻塞，如果问题节点的请求产生积压，则会导致所有下游节点线程被耗尽，这就是可怕的雪崩。